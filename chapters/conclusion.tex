\chapter{Conclusion} \label{sect:conclusion}

\paragraph{Summary}
We presented \acl, an algorithm for estimating level sets, which operates
based on confidence bounds derived by modeling the target function
as a GP. We considered for the first time the challenge of implicitly
defined threshold levels and extended \acl to this more complex setting.
We also showed how both algorithms can be extended to select samples
in batches. In addition, we provided theoretical bounds on the number of
iterations required to obtain an $\epsilon$-accurate solution when the target
function is sampled from a known GP.
The experiments on two real-world applications showed that \acl is
competitive with the state-of-the-art and in some cases shows much improved
results due to its more thorough exploration caused by its principled
classification scheme. Furthermore, the extensions we presented are successful
in handling the corresponding problem variants and perform significantly
better than naive baselines. We believe our results provide an important step
towards addressing complex real-world information gathering problems.

\paragraph{Future work}
As we have seen in the analysis of \iacl, its convergence to an accurate
solution is largely dictated by the difference $h^{opt}_t - h^{pes}_t$
and its rate of decrease. The algorithm as presented gives in a sense
``equal weight'' to sampling from ambiguous regions near the estimated
level set and to sampling near potential maximizers by using maximum
variance sampling among the points in $Z_t$.
However, we
expect that biasing the search early toward maximizers would result
in faster accurate estimates of the maximum, leading to lower values
of the above difference and, therefore, faster overall convergence.
Some preliminary experiments with using \gpucb's selection rule
every $k_t$ iterations, where $k_t$ starts with a small value and
increases over time, justify the above claims and lead to improved
performance. It would be interesting to theoretically explore such
a scheme and see if any improved convergence guarantees can be proven.

The presented method for path planning via batch point selection has
a number of shortcomings when applied in practice.
First, since the selection of each batch is decoupled from its evaluation,
there is no way to adjust the path according to the measurements obtained
during its traversal.
Second, while in practice we could obtain additional samples during the
traversal of an edge of the path (assuming that measurements are not
very costly), there is no easy way to incorporate this into our batch-based
algorithm. In particular, one would have to take into account the
estimated information gained from the additional samples when computing
each path.
Last, as can be seen in the example of \figref{fig:limno_bgape_ppbatch}
the resulting TSP path may contain several abrupt changes of direction that
are not achievable in practice due to kinematic constraints of the mobile
sensor equipment.
To deal with the above issues we are working on a graph-based
path-planning algorithm, which (1) explicitly incorporates kinematic
constraints into its graph structure, (2) takes into account the additional
samples acquired during edge traversal when computing the path,
and (3) replans after each step of the path using the newly obtained
measurements.

% Comments about implicit