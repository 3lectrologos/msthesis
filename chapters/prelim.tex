\chapter{Preliminaries} \label{ch:prelim}

\paragraph{Formal problem statement}
Given a function ${f : D \to \mathbb{R}}$, where $D$ is a
finite\footnote{The subsequent analysis only considers the finite domain case
for simplicity, however our results can be generalized to continuous spaces
as well \citep[cf.][]{srinivas10}.}
subset of $\mathbb{R}^d$, and a threshold level ${h \in \mathbb{R}}$,
we define the \emph{level set estimation problem} as the problem of classifying
every point $\*x \in D$ into a \emph{superlevel set}
${H = \{\*x \in D \mid f(\*x) > h\}}$ and a \emph{sublevel set}
${L = \{\*x \in D \mid f(\*x) \leq h\}}$.

When an explicit level is not available, we can define an
\emph{implicit threshold level}
with respect to the function maximum in either absolute or relative terms.
We use the relative definition in our exposition with
${h = \omega \max_{\*x\in D} f(\*x)}$
and $\omega \in (0, 1)$.

In the \emph{strictly sequential} setting,
at each step $t \geq 1$, we select a point $\*x_t \in D$ to be evaluated and
obtain a noisy measurement $y_t = f(\*x_t) + n_t$.
In the \emph{batch} setting we select $B$ points at a time and only obtain
the resulting measurements after all of the $B$ points have been selected.
This setting can be generalized by using the notion of a
\emph{feedback function} introduced by \citet{desautels12}.
In particular, we assume that there is a function
${\fb : \mathbb{N} \to \mathbb{N}\cup\{0\}}$, such that
$\fb[t] \leq t-1$ for all $t \geq 1$, and when selecting the next point
at time step $t$, we have access to evaluated measurements up to
time step $\fb[t]$. For selecting batches of size $B$ we can define
$\fb[1] = \ldots = \fb[B] = 0$,\enskip$\fb[B+1] = \ldots = \fb[2B] = B$,
and so on,
but the feedback function also allows for defining more complex cases
of delayed feedback.

\paragraph{Gaussian processes}
\looseness -1 Without any assumptions about the function $f$, attempting to estimate level sets from few samples is a hopeless endeavor.
%theoretically analyze our algorithms, we have to make some assumptions about the underlying function $f$.
Modeling $f$ as a sample from a Gaussian process
(GP) provides an elegant way for specifying properties of the function in a
nonparametric fashion. A GP is defined as a collection of random variables,
any finite subset of which is distributed according to a
multivariate Gaussian in a consistent way~\cite{rasmussen06}. A GP is
denoted as $\mathcal{GP}(\mu(\*x), k(\*x, \*x'))$ and is
completely specified by its mean function $\mu(\*x)$, which can be
assumed to be zero w.l.o.g., and its covariance function or kernel
$k(\*x, \*x')$, which encodes smoothness properties of functions sampled
from the GP.

Assuming a GP prior $\mathcal{GP}(0, k(\*x, \*x'))$ over $f$ and given
$t$ noisy measurements $\*y_{1:t} = [y_1,\ldots,y_t]^T$ for
points in $A_t = \{x_1,\ldots,x_t\}$,
where $y_i = f(\*x_i) + n_i$ and
${n_i \sim \mathcal{N}(0, \sigma^2)}$ (Gaussian i.i.d. noise)
for $i = 1,\ldots,t$, the posterior over $f$ is also a
GP and its mean, covariance, and variance functions are given by the
following analytic formulae:
\begin{align}
\mu_t(\*x) &= \*k_t(\*x)^T\left(\*K_t + \sigma^2 \*I\right)^{-1}\*y_t\label{eq:mean}\\
k_t(\*x, \*x') &= k(\*x, \*x') - \*k_t(\*x)^T\left(\*K_t + \sigma^2 \*I\right)^{-1}\*k_t(\*x)\notag\\
\sigma_t^2(\*x) &= k_t(\*x, \*x)\label{eq:var},
\end{align}
where $\*k_t(\*x) = [k(\*x_1, \*x),\ldots,k(\*x_t, \*x)]^T$ and $\*K_t$ is
the kernel matrix of already observed points, defined as
${\*K_t = [k(\*x, \*x')]_{\*x, \*x'\in A_t}}$.

\paragraph{Information gain}
The information gain about a random variable $X$ from observing a random
variable $Y$, also known as the \emph{mutual information} of the two variables,
is defined as~\cite{cover06}
\begin{align*}
I(X; Y) = H(X) - H(X\mid Y),
\end{align*}
where $H(X)$ is the entropy of $X$ and $H(X\mid Y)$ is the conditional
entropy of $X$ given $Y$.
The information gain is symmetric, i.e. $I(X; Y) = I(Y; X)$, and,
as can be seen from the above definition, it quantifies the (average) reduction
in our uncertainty about $X$ when observing the value of $Y$ (and vice
versa).

We will use the information gain to quantify the reduction in uncertainty
about $f \sim \mathcal{GP}(0, k(\*x, \*x'))$ when obtaining a set of
noisy observations $\*y_{1:t}$, which is
\begin{align*}
I(f; \*y_{1:t}) = I(\*y_{1:t}; f) = H(\*y_{1:t}) - H(\*y_{1:t}\mid f).
\end{align*}
If we define $f_i = f(\*x_i)$, from the fact that
$\*y_{1:t} = \*f_{1:t} + \*n_{1:t}$ is a sum of Gaussians, it follows that
$\*y_{1:t} \sim \mathcal{N}\left(0, \*K_t + \sigma^2 I\right)$ and the
entropy of the noisy observations is
\begin{align}\label{eq:hy}
H(\*y_{1:t}) = \frac{1}{2}\log\left((2\pi e)^t |\*K_t + \sigma^2 I|\right).
\end{align}
Furthermore, note that the observations $\*y_{1:t}$ are conditionally
independent of anything else given the underlying GP values
of $\*f_{1:t}$ and
$\*y_{1:t}\mid \*f_{1:t} \sim \mathcal{N}(\*f_{1:t}, \sigma^2 I)$.
It follows that
\begin{align}\label{eq:hyf}
H(\*y_{1:t}\mid f) = H(\*y_{1:t}\mid \*f_{1:t}) = \frac{1}{2}\log\left((2\pi e)^t |\sigma^2 I|\right).
\end{align}
Combining \eqtref{eq:hy} and \eqtref{eq:hyf} we get
\begin{align*}
I(f; \*y_{1:t}) = \frac{1}{2}\log\left(|I + \sigma^{-2} \*K_t|\right)
\end{align*} 

The notion of information gain can be generalized to the \emph{conditional
information gain} or \emph{conditional mutual information}, which quantifies
the reduction in uncertainty about a variable $X$ from observing the value
of a variable $Y$ when already given the value of variable $Z$. It is
similarly defined as
\begin{align*}
I(X; Y\mid Z) = H(X\mid Z) - H(X\mid Y, Z).
\end{align*} We will use it to quantify the reduction in uncertainty about $f$ when
obtaining a set of additional noisy observations $\*y_A$ given that
we already have available observations $\*y_{1:t}$, which is
\begin{align*}
I(f; \*y_A\mid \*y_{1:t}) &= H(\*y_A\mid \*y_{1:t}) - H(\*y_A\mid \*y_{1:t}, f)\\
                          &= H(\*y_A\mid \*y_{1:t}) - H(\*y_A\mid f)\\
                          &= I(f; \*y_{1:t}) = \frac{1}{2}\log\left(|I + \sigma^{-2} \*K^t_A|\right),
\end{align*}
using a similar derivation to above and defining
${\*K^t_A = [k_t(\*x, \*x')]_{\*x, \*x'\in\*A}}$.