\chapter{Introduction} \label{ch:intro}
Many information gathering problems 
%It is often the case in practical applications, that we are primarily
%interested in 
require accurately determining the regions where the value of some
unknown function lies above or below a given threshold level.
%, whereas
% modeling the precise behavior of the function inside those regions is of
%secondary concern. 
Moreover, evaluating the function is usually a costly
procedure and the measurements returned are noisy.

As a concrete example of such an application, consider the task of
monitoring a lake environment (in our case Lake Zurich) for algal bloom,
a phenomenon that is potentially harmful to other organisms of the ecosystem.
One way to accomplish this is by
determining the regions of the lake where the levels of algae-produced
chlorophyll (see \figref{fig:limno_chl}) and
algae (see \figref{fig:limno_bgape}) concentration lie above some threshold
value determined by field experts.
These regions can be estimated by sampling
at various locations of the lake using a mobile sensing device.
However, each measurement is costly in terms of time and sensor battery power,
therefore the sampling locations have to be picked carefully, in order to
reduce the total number of measurements required.

%\setlength\figureheight{1.5in}\setlength\figurewidth{3.5in}
%\input{figures/ch01/limno_chl_fp.tex}
%\input{figures/ch01/limno_chl_res.tex}
\renewcommand\trimlen{0pt}
\begin{figure}[tb]
  \begin{subfigure}[b]{\linewidth}
    \centering
    \adjincludegraphics[width=0.8\linewidth,clip=true,trim=\trimlen{} \trimlen{} \trimlen{} \trimlen{}]{figures/ch01/limno_chl_fp}
    \caption{Ground truth}
    \label{fig:limno_chl}
  \end{subfigure}
  \begin{subfigure}[b]{\linewidth}
    \centering
    \vspace{12pt} % space of this row from above captions
    \hspace{-2.3em}
    \adjincludegraphics[width=0.735\linewidth,clip=true,trim=\trimlen{} \trimlen{} \trimlen{} \trimlen{}]{figures/ch01/limno_chl_res}
    \caption{Estimated level set}
    \label{fig:limno_chl_res}
  \end{subfigure}
  \caption{\textbf{(a)} Chlorophyll concentration in relative fluorescence units (RFU)
           inferred from $2024$ measurements within a vertical transect plane
           of Lake Zurich (target level set at $h = 1.3$ RFU shown dashed).
           \textbf{(b)} Estimated classification into superlevel (orange) and
           sublevel (blue) sets after $405$ samples using our proposed \acl algorithm.}
  \label{fig:limno_chl_all}
\end{figure}

Other example applications in the context of environmental
monitoring~\cite{rahimi04} include estimating level sets of quantities
such as solar radiation, humidity, etc., and determining
the extent of hazardous phenomena, e.g. air pollution or
oil spills~\cite{galland04}.
In a different category are applications that consist in determining
the subset of a
parameter space that represents ``acceptable'' hypotheses~\cite{bryan05} or
designs~\cite{ramakrishnan05}.

We consider the problem of estimating some function level set
in a sequential decision setting, where, at each time step, the
next sampling location is to be selected given all previous measurements.
For solving this problem, we propose the \fullacl (\acl) algorithm,
which utilizes Gaussian processes~\cite{rasmussen06} to model the target
function and exploits inferred variance estimates to create confidence bounds
and drive the selection process.
We also provide an information-theoretic bound
on the number of measurements needed to achieve a certain accuracy,
when the underlying function is sampled from a known Gaussian process.

\figref{fig:limno_chl_res} shows the estimated super- and sublevel sets
resulting from running \acl on the chlorophyll concentration dataset of
\figref{fig:limno_chl}. Intuitively, \acl works by progressively classifying
points into the super- and sublevel sets and, at the same time, sampling
at regions of high ``ambiguity'', i.e. regions where there is high
uncertainty about whether the value of the function lies above or below
the specified threshold level. As a consequence, the vast majority of
the sampled locations are concentrated near the level set to be estimated,
as is clearly shown in the above figure.

Furthermore, we extend the \acl algorithm to two more settings that
naturally arise in practical applications.
In the first setting, we do not a priori have a specific threshold level
at our disposal, but would still like to perform level set estimation with
respect to an \emph{implicit} level that is expressed as a percentage
of the function maximum. In the environmental monitoring application outlined
above, we might want to estimate regions of relatively high algae
concentration, where what is considered as ``high'' concentration might
depend on the season of the year or other environmental factors. Using
an implicit threshold level gives us a way to obtain useful information
without the need to hardcode a prespecified threshold level of interest
into the algorithm.

\figref{fig:limno_bgape_res} shows the estimated super- and sublevel sets
resulting from running \acl on the chlorophyll concentration dataset of
\figref{fig:limno_bgape} using an implicit threshold level of $75\%$ of
the maximum. While the element of gradual classification of the explicit
threshold algorithm is also present in the implicit version, there is an
additional
complexity of estimating the function maximum, in order to obtain accurate
estimates of the implicit level. Therefore, while the algorithm still
focuses on the ``ambiguous'' regions of the input space, at the same time
it also heavily samples near the regions of the function maxima.

%\setlength\figureheight{1.5in}\setlength\figurewidth{3.5in}
%\input{figures/ch01/limno_bgape_fp.tex}
%\input{figures/ch01/limno_bgape_res.tex}
\renewcommand\trimlen{0pt}
\begin{figure}[tb]
  \begin{subfigure}[b]{\linewidth}
    \centering
    \adjincludegraphics[width=0.8\linewidth,clip=true,trim=\trimlen{} \trimlen{} \trimlen{} \trimlen{}]{figures/ch01/limno_bgape_fp}
    \caption{Ground truth}
    \label{fig:limno_bgape}
  \end{subfigure}
  \begin{subfigure}[b]{\linewidth}
    \centering
    \vspace{12pt} % space of this row from above captions
    \hspace{-1.7em}
    \adjincludegraphics[width=0.75\linewidth,clip=true,trim=\trimlen{} \trimlen{} \trimlen{} \trimlen{}]{figures/ch01/limno_bgape_res}
    \caption{Estimated level set}
    \label{fig:limno_bgape_res}
  \end{subfigure}
  \caption{\textbf{(a)} Algae concentration in relative fluorescence units (RFU)
           inferred from $2024$ measurements within a vertical transect plane
           of Lake Zurich (target level set at $h = 0.75\max f(\*x) = 7$ RFU shown
           dashed).
           \textbf{(b)} Estimated classification into superlevel (orange) and
           sublevel (blue) sets after $405$ samples using the implicit version
           of the \acl algorithm.}
  \label{fig:limno_bgape_all}
\end{figure}

The second extension applies to both the explicit and implicit versions of
the algorithm and aims at selecting at each step a \emph{batch} of next
samples, rather than just one sample at a time. A reason for doing so is that,
in problems such as the lake sensing example outlined above,
apart from the cost of actually taking each measurement, we
also have to take into account the cost incurred by traveling from one
sampling location to the next. Traveling costs can be dramatically reduced,
if we plan ahead by selecting multiple points at a time. Another reason is
that some problems allow for running multiple function evaluations in
parallel, in which case selecting batches of points can lead to a
significant increase in sampling throughput.

\paragraph{Contributions}
The main contributions of this thesis can be summarized as follows:
\begin{itemize}
\item We introduce the \acl algorithm for sequentially estimating level sets
      of unknown functions and also extend it to select samples in batches.
\item We consider for the first time the problem of estimating level sets under
      implicitly defined threshold levels and propose an extension of \acl
      for this problem.
\item We prove theoretical convergence bounds for \acl and its two
      extensions when the target function is sampled from a known GP.
\item We evaluate \acl and its extensions on three real-world datasets and show
      that they are competitive with the state-of-the-art.
\end{itemize}

\section{Related work}
Previous work on level set~\cite{dantu07,srinivasan08} and
boundary~\cite{singh06} estimation and tracking in the context of mobile
sensor networks has primarily focused on controlling the movement and
communication of sensor nodes, without giving much attention to
individual sampling locations and the choice thereof.

In contrast, we consider the problem of level set estimation in the setting of
\emph{pool-based active learning}~\cite{settles09}, where we need to make
sequential decisions by choosing sampling locations from a given set.
For this problem, \citet{bryan05} have proposed the
\emph{straddle} heuristic, which selects where to sample by trading off
uncertainty and proximity to the desired threshold level, both estimated
using GPs.
However, no theoretical justification has been given for the use of straddle,
neither for its extension to composite functions~\cite{bryan08}.
\citet{garnett12} consider the problem of
\emph{active search}, which is also about sequential sampling from a domain of
two (or more) classes (in our case the super- and sublevel sets).
In contrast to our goal of detecting the class boundaries, however,
their goal is to sample as many points as possible from one of the classes.

In the setting of multi-armed bandit optimization, which is similar to ours
in terms of sequential sampling, but different in terms of objectives,
GPs have been used both for modeling, as well as for sample
selection~\mbox{\cite{brochu10}}. In particular, the \gpucb algorithm
makes use of GP-inferred upper confidence bounds for selecting samples and
has been shown to achieve sublinear regret~\cite{srinivas10}.
An extension of \gpucb to the multi-objective
optimization problem has been proposed by
\citet{zuluaga13}, who use a similar GP-based
classification scheme to ours to classify points as being Pareto-optimal
or not.

Existing approaches for performing multiple evaluations in
parallel in the context of GP optimization, include
\emph{simulation matching}~\cite{azimi10}, which combines GP modeling with
Monte-Carlo simulations, and the \gpbucb~\cite{desautels12} algorithm,
which obtains similar regret bounds to \gpucb, and from which we borrow
the main idea for performing batch sample selection.

To our knowledge, there has been no previous work on actively estimating
level sets with respect to implicitly defined threshold levels.

\section{Formal problem statement} \label{sect:prelim}

Given a function ${f : D \to \mathbb{R}}$, where $D$ is a
finite\footnote{The subsequent analysis only considers the finite domain case
for simplicity, however our results can be generalized to continuous spaces
as well \citep[cf.][]{srinivas10}.}
subset of $\mathbb{R}^d$, and a threshold level ${h \in \mathbb{R}}$,
we define the \emph{level set estimation problem} as the problem of classifying
every point $\*x \in D$ into a \emph{superlevel set}
${H = \{\*x \in D \mid f(\*x) > h\}}$ and a \emph{sublevel set}
${L = \{\*x \in D \mid f(\*x) \leq h\}}$.

When an explicit level is not available, we can define an
\emph{implicit threshold level}
with respect to the function maximum in either absolute or relative terms.
We use the relative definition in our exposition with
${h = \omega \max_{\*x\in D} f(\*x)}$
and $\omega \in (0, 1)$.

In the \emph{strictly sequential} setting,
at each step $t \geq 1$, we select a point $\*x_t \in D$ to be evaluated and
obtain a noisy measurement $y_t = f(\*x_t) + n_t$.
In the \emph{batch} setting we select $B$ points at a time and only obtain
the resulting measurements after all of the $B$ points have been selected.
This setting can be generalized by using the notion of a
\emph{feedback function} introduced by \citet{desautels12}.
In particular, we assume that there is a function
${\fb : \mathbb{N} \to \mathbb{N}\cup\{0\}}$, such that
$\fb[t] \leq t-1$ for all $t \geq 1$, and when selecting the next point
at time step $t$, we have access to evaluated measurements up to
time step $\fb[t]$. For selecting batches of size $B$ we can define
$\fb[1] = \ldots = \fb[B] = 0$,\enskip$\fb[B+1] = \ldots = \fb[2B] = B$,
and so on,
but the feedback function also allows for defining more complex cases
of delayed feedback.

\section{Gaussian processes}
\looseness -1 Without any assumptions about the function $f$, attempting to estimate level sets from few samples is a hopeless endeavor.
%theoretically analyze our algorithms, we have to make some assumptions about the underlying function $f$.
Modeling $f$ as a sample from a Gaussian process
(GP) provides an elegant way for specifying properties of the function in a
nonparametric fashion. A GP is defined as a collection of random variables,
any finite subset of which is distributed according to a
multivariate Gaussian in a consistent way~\cite{rasmussen06}. A GP is
denoted as $\mathcal{GP}(\mu(\*x), k(\*x, \*x'))$ and is
completely specified by its mean function $\mu(\*x)$, which can be
assumed to be zero w.l.o.g., and its covariance function or kernel
$k(\*x, \*x')$, which encodes smoothness properties of functions sampled
from the GP.

Assuming a GP prior $\mathcal{GP}(0, k(\*x, \*x'))$ over $f$ and given
$t$ noisy measurements $\*y_t = [y_1,\ldots,y_t]^T$ for
points in $A_t = \{x_1,\ldots,x_t\}$,
where $y_i = f(\*x_i) + n_i$ and
${n_i \sim \mathcal{N}(0, \sigma^2)}$ (Gaussian i.i.d. noise)
for $i = 1,\ldots,t$, the posterior over $f$ is also a
GP and its mean, covariance, and variance functions are given by the
following analytic formulae:
\begin{align}
\mu_t(\*x) &= \*k_t(\*x)^T\left(\*K_t + \sigma^2 \*I\right)^{-1}\*y_t\label{eq:mean}\\
k_t(\*x, \*x') &= k(\*x, \*x') - \*k_t(\*x)^T\left(\*K_t + \sigma^2 \*I\right)^{-1}\*k_t(\*x)\notag\\
\sigma_t^2(\*x) &= k_t(\*x, \*x)\label{eq:var},
\end{align}
where $\*k_t(\*x) = [k(\*x_1, \*x),\ldots,k(\*x_t, \*x)]^T$ and $\*K_t$ is
the kernel matrix of already observed points, defined as
${\*K_t = [k(\*x, \*x')]_{\*x, \*x'\in\*A_t}}$.
